# **Wine Quality Prediction Analysis**

## **ğŸŒŸ Overview**
This project focuses on predicting wine quality based on its chemical properties using Machine Learning techniques. The goal is to classify wines as either Good or Bad, leveraging various feature selection methods and supervised learning algorithms. By analyzing and visualizing key characteristics, this project aims to extract valuable insights that can help winemakers improve their products.

## **â“ Why This Project?**
Wine quality assessment traditionally relies on expert sensory evaluation, which is time-consuming and subjective. This project aims to develop an automated and data-driven approach to predict wine quality efficiently.<br>
Key motivations:<br>
âœ… Improve wine classification accuracy using ML models.<br>
âœ… Identify the most important chemical components influencing wine quality.<br>
âœ… Compare different classification models to find the best-performing one.<br>

## **ğŸ”‘ Key Features & Learnings**
ğŸ”¹ Exploratory Data Analysis (EDA) to uncover trends in wine quality.<br>
ğŸ”¹ Feature Engineering to enhance prediction accuracy.<br>
ğŸ”¹ Comparison of multiple ML models (Logistic Regression, Decision Tree, Random Forest).<br>
ğŸ”¹ Hyperparameter tuning to optimize model performance.<br>
ğŸ”¹ Model evaluation using metrics like Accuracy, Precision, Recall, F1-Score.<br>
ğŸ”¹ Data Visualization for deeper insights into chemical influences.<br>

## **ğŸ›  Technologies, Tools, and Frameworks**
ğŸ”¹ Programming Language:	Python<br>
ğŸ”¹ Data Processing:	Pandas, NumPy<br>
ğŸ”¹ Data Visualization:	Matplotlib, Seaborn<br>
ğŸ”¹ Machine Learning:	Scikit-learn<br>
ğŸ”¹ Feature Engineering:	PCA, StandardScaler<br>
ğŸ”¹ Model Tuning:	GridSearchCV<br>
ğŸ”¹ Notebook: Jupyter Notebook<br>

## **ğŸš€ Data Source**
The dataset used in this project is the Wine Quality Dataset from Kaggle.<br>
ğŸ”¹ Features: 11 physicochemical attributes (e.g., acidity, alcohol content).<br>
ğŸ”¹ Target: Wine quality score (0-10), converted to binary classification (Good or Bad).<br>

## **ğŸ‘‰ Installation & Usage**
ğŸ“Œ Prerequisites<br>
Ensure you have the following installed:<br>
âœ… Python 3.8+<br>
âœ… Jupyter Notebook<br>
âœ… Required Python libraries<br>

**Quick Start**


## **ğŸ“Š Exploratory Data Analysis (EDA)**
EDA helps uncover patterns and relationships between wine attributes.<br>
Key observations:<br>
ğŸ“Œ Alcohol content has a strong positive correlation with wine quality.<br>
ğŸ“Œ Volatile acidity negatively impacts qualityâ€”higher acidity = lower ratings.<br>
ğŸ“Œ Outliers in pH and sulfur dioxide levels were detected and handled.<br>

## **ğŸ” Key Visualizations**
ğŸ”¹ Correlation Heatmap: To identify relationships between variables.
ğŸ”¹ Boxplots: To detect outliers.
ğŸ”¹ Histogram Distribution: To understand feature distributions.

## **ğŸ”¬ Model Selection & Evaluation**

ğŸ“Œ Random Forest performed the best, achieving 85% accuracy due to its robustness against overfitting.

## **ğŸ›  Feature Engineering & Selection**
Feature selection and engineering play a crucial role in model performance.<b>
ğŸ”¹ One-hot encoding applied for categorical features.<b>
ğŸ”¹ StandardScaler used for normalizing numerical features.<b>
ğŸ”¹ Principal Component Analysis (PCA) reduced dimensionality from 11 to 8 features, improving model efficiency.<b>

## **âš¡ Hyperparameter Tuning**
Using GridSearchCV, we optimized Random Forest hyperparameters:<b>
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20],
    'min_samples_split': [2, 5, 10]
}
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print(grid_search.best_params_)<b>
âœ… Best parameters found: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5}

> [!NOTE]
> Useful information that users should know, even when skimming content.

> [!TIP]
> Helpful advice for doing things better or more easily.

> [!IMPORTANT]
> Key information users need to know to achieve their goal.

> [!WARNING]
> Urgent info that needs immediate user attention to avoid problems.

> [!CAUTION]
> Advises about risks or negative outcomes of certain actions.

## **ğŸ¯ Key Insights & Conclusions**
The analysis revealed that alcohol content is the most significant factor influencing wine quality, highlighting its strong correlation with higher ratings. Among the models tested, Random Forest demonstrated superior performance, outperforming both Logistic Regression and Decision Tree in predictive accuracy. Additionally, feature engineering effortsâ€”such as handling missing values, balancing the dataset, and selecting the most relevant featuresâ€”led to a 10% improvement in model accuracy, further enhancing its reliability. These insights provide valuable guidance for winemakers, enabling them to adjust chemical compositions strategically to optimize wine quality and maintain consistency in production.
